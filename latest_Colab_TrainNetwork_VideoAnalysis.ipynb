{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " latest_Colab_TrainNetwork_VideoAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dheyala28/dheyala28/blob/master/latest_Colab_TrainNetwork_VideoAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK255E7YoEIt"
      },
      "source": [
        "# DeepLabCut Toolbox - Colab for standard (single animal) projects!\n",
        "https://github.com/DeepLabCut/DeepLabCut\n",
        "\n",
        "This notebook illustrates how to use the cloud to:\n",
        "- create a training set\n",
        "- train a network\n",
        "- evaluate a network\n",
        "- create simple quality check plots\n",
        "- analyze novel videos!\n",
        "\n",
        "###This notebook assumes you already have a project folder with labeled data! \n",
        "\n",
        "This notebook demonstrates the necessary steps to use DeepLabCut for your own project.\n",
        "\n",
        "This shows the most simple code to do so, but many of the functions have additional features, so please check out the overview & the protocol paper!\n",
        "\n",
        "Nath\\*, Mathis\\* et al.: Using DeepLabCut for markerless pose estimation during behavior across species. Nature Protocols, 2019.\n",
        "\n",
        "\n",
        "Paper: https://www.nature.com/articles/s41596-019-0176-0\n",
        "\n",
        "Pre-print: https://www.biorxiv.org/content/biorxiv/early/2018/11/24/476531.full.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txoddlM8hLKm"
      },
      "source": [
        "## First, go to \"Runtime\" ->\"change runtime type\"->select \"Python3\", and then select \"GPU\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q23BzhA6CXxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b9ccdef-84e4-4966-9037-9504a1a3e872"
      },
      "source": [
        "#(this will take a few minutes to install all the dependences!)\n",
        "!pip install deeplabcut"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deeplabcut\n",
            "  Downloading deeplabcut-2.2.1.1-py3-none-any.whl (591 kB)\n",
            "\u001b[K     |████████████████████████████████| 591 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.21.6)\n",
            "Collecting numba>=0.54\n",
            "  Downloading numba-0.55.2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 65.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.6 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2.6.3)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.13)\n",
            "Collecting statsmodels!=0.13.2,>=0.11\n",
            "  Downloading statsmodels-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 45.9 MB/s \n",
            "\u001b[?25hCollecting tensorpack>=0.11\n",
            "  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[K     |████████████████████████████████| 296 kB 69.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (7.1.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.4.1)\n",
            "Requirement already satisfied: scikit-image<=1.0.0,>=0.17 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.18.3)\n",
            "Collecting ruamel.yaml>=0.15.0\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 74.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2.8.2+zzzcolab20220527125636)\n",
            "Collecting tf-slim>=1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 67.3 MB/s \n",
            "\u001b[?25hCollecting filterpy>=1.4.4\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 66.6 MB/s \n",
            "\u001b[?25hCollecting matplotlib>=3.3\n",
            "  Downloading matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tables>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.7.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->deeplabcut) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->deeplabcut) (1.15.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->deeplabcut) (1.8.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->deeplabcut) (4.1.2.30)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3->deeplabcut) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3->deeplabcut) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3->deeplabcut) (3.0.9)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.34.0-py3-none-any.whl (943 kB)\n",
            "\u001b[K     |████████████████████████████████| 943 kB 63.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3->deeplabcut) (1.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3->deeplabcut) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.3->deeplabcut) (4.1.1)\n",
            "Collecting llvmlite<0.39,>=0.38.0rc1\n",
            "  Downloading llvmlite-0.38.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 7.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.54->deeplabcut) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->deeplabcut) (2022.1)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image<=1.0.0,>=0.17->deeplabcut) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image<=1.0.0,>=0.17->deeplabcut) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->deeplabcut) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels!=0.13.2,>=0.11->deeplabcut) (0.5.2)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables>=3.7.0->deeplabcut) (2.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (0.26.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.6.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.14.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (14.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.46.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->deeplabcut) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.0->deeplabcut) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (3.2.0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack>=0.11->deeplabcut) (1.0.4)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack>=0.11->deeplabcut) (23.1.0)\n",
            "Collecting msgpack-numpy>=0.4.4.2\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack>=0.11->deeplabcut) (5.4.8)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack>=0.11->deeplabcut) (0.8.9)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110474 sha256=02b682959ab5d663d9fa7d7c2418cb617ab0ea6e50c81b7ea415101062b9e3f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/e0/ee/a2b3c5caab3418c1ccd8c4de573d4cbe13315d7e8b0a55fbc2\n",
            "Successfully built filterpy\n",
            "Installing collected packages: fonttools, matplotlib, ruamel.yaml.clib, msgpack-numpy, llvmlite, tf-slim, tensorpack, statsmodels, ruamel.yaml, numba, imgaug, filterpy, deeplabcut\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed deeplabcut-2.2.1.1 filterpy-1.4.5 fonttools-4.34.0 imgaug-0.4.0 llvmlite-0.38.1 matplotlib-3.5.2 msgpack-numpy-0.4.8 numba-0.55.2 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 statsmodels-0.13.1 tensorpack-0.11 tf-slim-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25wSj6TlVclR"
      },
      "source": [
        "**(Be sure to click \"RESTART RUNTIME\" is it is displayed above above before moving on !)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y36K4Eux3h-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "584ee976-b840-4712-bb99-acc186b1fd0e"
      },
      "source": [
        "# Use TensorFlow 1.x:\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ-nlTkri4HZ"
      },
      "source": [
        "## Link your Google Drive (with your labeled data, or the demo data):\n",
        "\n",
        "### First, place your project folder into you google drive! \"i.e. move the folder named \"Project-YourName-TheDate\" into google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS4Q4UkR9rgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80f78f89-24e3-430a-ba21-a4097fc4db80"
      },
      "source": [
        "#Now, let's link to your GoogleDrive. Run this cell and follow the authorization instructions:\n",
        "#(We recommend putting a copy of the github repo in your google drive if you are using the demo \"examples\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frnj1RVDyEqs"
      },
      "source": [
        "YOU WILL NEED TO EDIT THE PROJECT PATH **in the config.yaml file** TO BE SET TO YOUR GOOGLE DRIVE LINK!\n",
        "\n",
        "Typically, this will be: /content/drive/My Drive/yourProjectFolderName\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhENAlQnFENJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1646ec-cf3c-471b-a7ff-e2ffd7a51c12"
      },
      "source": [
        "#Setup your project variables:\n",
        "# PLEASE EDIT THESE:\n",
        "  \n",
        "ProjectFolderName = 'B-SOIDdlc-Dheyala-2022-07-05'\n",
        "VideoType = 'mp4' \n",
        "\n",
        "#don't edit these:\n",
        "videofile_path = ['/content/drive/My Drive/'+ProjectFolderName+'/videos/'] #Enter the list of videos or folder to analyze.\n",
        "videofile_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXufoX6INe6w"
      },
      "source": [
        "#GUIs don't work on the cloud, so label your data locally on your computer! This will suppress the GUI support\n",
        "import os\n",
        "os.environ[\"DLClight\"]=\"True\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K9Ndy1beyfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dda1156-c50d-4a1d-9582-d523bd1d6b34"
      },
      "source": [
        "import deeplabcut"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DLC 2.2.1.1...\n",
            "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4orkg9QTHKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d94f2dc2-e5e9-47b2-c142-4d0a8b5c6794"
      },
      "source": [
        "deeplabcut.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.1.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7ZlDr3wV4D1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2784a0b6-1e7a-43d6-f667-f0c96d64aec0"
      },
      "source": [
        "#This creates a path variable that links to your google drive copy\n",
        "#No need to edit this, as you set it up before: \n",
        "path_config_file = '/content/drive/My Drive/'+ProjectFolderName+'/config.yaml'\n",
        "path_config_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/config.yaml'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNi9s1dboEJN"
      },
      "source": [
        "## Create a training dataset:\n",
        "### You must do this step inside of Colab:\n",
        "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
        "\n",
        "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
        "\n",
        "Now it is the time to start training the network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eMeUwgxPoEJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c481a0f1-881e-4255-9ab1-9c1033674375"
      },
      "source": [
        "# Note: if you are using the demo data (i.e. examples/Reaching-Mackenzie-2018-08-30/), first delete the folder called dlc-models! \n",
        "#Then, run this cell. There are many more functions you can set here, including which netowkr to use!\n",
        "#check the docstring for full options you can do!\n",
        "deeplabcut.create_training_dataset(path_config_file, net_type='resnet_50', augmenter_type='imgaug')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading a ImageNet-pretrained model from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz....\n",
            "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.95,\n",
              "  1,\n",
              "  (array([181, 258,  15,  65, 216,  63, 240, 228, 167, 156,  64, 103, 124,\n",
              "          315, 310,  60, 122, 271,  66,  26, 286, 158, 136, 309, 164, 200,\n",
              "          272,   7,   6, 230, 254,  22, 152,  21,  55, 157,  12, 108,  68,\n",
              "          144, 170, 278,  59, 134, 231,  92, 175, 267,  74,  81, 288, 259,\n",
              "          264,  52, 133, 176,  56,  90, 248,  17,   1,   8, 150, 206, 209,\n",
              "          140, 217, 194,   5,  33, 280,  34, 212, 215, 263, 137,  45, 101,\n",
              "          266, 126, 198, 238, 199, 222, 120, 245, 135,  73, 313, 304, 116,\n",
              "          255,  29,  97,  20,  46, 213, 262, 312,  89, 250,  27, 319, 311,\n",
              "           37,  54, 236, 260, 142, 132, 184, 190, 303, 239, 159, 161,  35,\n",
              "          102,  76, 106, 171, 225, 282, 160, 179, 173, 301,  44, 145, 129,\n",
              "          226, 111, 188, 166,  18, 196,  79,  71, 168, 269, 307, 146, 189,\n",
              "           83, 291, 118, 153, 299, 110, 220,  16,  75, 109, 208, 191, 139,\n",
              "            4,  96, 234,  61,  67, 154, 300, 235, 253, 298,  40, 221,  13,\n",
              "          107, 233,   3, 210, 125,  24,  30,  77, 296, 223, 219,  19, 273,\n",
              "          275, 182, 284,  80,  51,   2,  11, 104, 214,  86,  10, 229, 305,\n",
              "           58,  41,  14, 155,  50, 249, 302, 287, 314, 123, 237,  62, 224,\n",
              "          261, 130, 187, 246, 218, 247,  43, 114, 138, 252, 268, 201, 149,\n",
              "          112, 205, 270,  98, 256,  93, 241, 162,  36, 178, 113,   0,  94,\n",
              "          294,  95, 316, 279, 169,  69,  49,  48,  85, 317, 141, 207,  23,\n",
              "          186, 227, 148, 143,  78, 232, 180, 100, 204, 131, 290, 318, 203,\n",
              "           84, 121, 274, 293,  91,  82, 119,  57, 257, 283,  42, 105, 281,\n",
              "           38,  53, 276, 128,  28, 183, 163, 151, 244, 202,  31,  32, 127,\n",
              "          185, 297, 289, 147, 285, 295, 177,  99, 197, 243, 115, 265,  72,\n",
              "           25, 165, 306, 174, 308]),\n",
              "   array([ 39, 193,  88,  70,  87, 292, 242, 277, 211,   9, 195, 251, 192,\n",
              "          117,  47, 172])))]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4FczXGDoEJU"
      },
      "source": [
        "## Start training:\n",
        "This function trains the network for a specific shuffle of the training dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pOvDq_2oEJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "09e3424e-3a55-48eb-9d7f-9155fe534768"
      },
      "source": [
        "#let's also change the display and save_iters just in case Colab takes away the GPU... \n",
        "#if that happens, you can reload from a saved point. Typically, you want to train to 200,000 + iterations.\n",
        "#more info and there are more things you can set: https://github.com/DeepLabCut/DeepLabCut/wiki/DOCSTRINGS#train_network\n",
        "\n",
        "deeplabcut.train_network(path_config_file, shuffle=1, displayiters=10,saveiters=500)\n",
        "\n",
        "#this will run until you stop it (CTRL+C), or hit \"STOP\" icon, or when it hits the end (default, 1.03M iterations). \n",
        "#Whichever you chose, you will see what looks like an error message, but it's not an error - don't worry...."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "iteration: 201970 loss: 0.0025 lr: 0.02\n",
            "iteration: 201980 loss: 0.0026 lr: 0.02\n",
            "iteration: 201990 loss: 0.0025 lr: 0.02\n",
            "iteration: 202000 loss: 0.0018 lr: 0.02\n",
            "iteration: 202010 loss: 0.0021 lr: 0.02\n",
            "iteration: 202020 loss: 0.0020 lr: 0.02\n",
            "iteration: 202030 loss: 0.0023 lr: 0.02\n",
            "iteration: 202040 loss: 0.0019 lr: 0.02\n",
            "iteration: 202050 loss: 0.0021 lr: 0.02\n",
            "iteration: 202060 loss: 0.0022 lr: 0.02\n",
            "iteration: 202070 loss: 0.0018 lr: 0.02\n",
            "iteration: 202080 loss: 0.0019 lr: 0.02\n",
            "iteration: 202090 loss: 0.0020 lr: 0.02\n",
            "iteration: 202100 loss: 0.0019 lr: 0.02\n",
            "iteration: 202110 loss: 0.0022 lr: 0.02\n",
            "iteration: 202120 loss: 0.0026 lr: 0.02\n",
            "iteration: 202130 loss: 0.0016 lr: 0.02\n",
            "iteration: 202140 loss: 0.0021 lr: 0.02\n",
            "iteration: 202150 loss: 0.0022 lr: 0.02\n",
            "iteration: 202160 loss: 0.0016 lr: 0.02\n",
            "iteration: 202170 loss: 0.0024 lr: 0.02\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9a4759324dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#more info and there are more things you can set: https://github.com/DeepLabCut/DeepLabCut/wiki/DOCSTRINGS#train_network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#this will run until you stop it (CTRL+C), or hit \"STOP\" icon, or when it hits the end (default, 1.03M iterations).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             )  # pass on path and file name for pose_cfg.yaml!\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         [_, loss_val, summary] = sess.run(\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         )\n\u001b[1;32m    275\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiDwIVf5-3H_"
      },
      "source": [
        "**When you hit \"STOP\" you will get a KeyInterrupt \"error\"! No worries! :)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZygsb2DoEJc"
      },
      "source": [
        "## Start evaluating:\n",
        "This function evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
        "and stores the results as .csv file in a subdirectory under **evaluation-results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv4zlbrnoEJg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "f5f20208-2476-4eb1-bc59-517555729550"
      },
      "source": [
        "%matplotlib notebook\n",
        "deeplabcut.evaluate_network(path_config_file,plotting=True)\n",
        "\n",
        "# Here you want to see a low pixel error! Of course, it can only be as good as the labeler, \n",
        "#so be sure your labels are good! (And you have trained enough ;)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config:\n",
            "{'all_joints': [[0], [1], [2], [3]],\n",
            " 'all_joints_names': ['nose', 'leftear', 'rightear', 'tailbase'],\n",
            " 'batch_size': 1,\n",
            " 'crop_pad': 0,\n",
            " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_B-SOIDdlcJul5/B-SOIDdlc_Dheyala95shuffle1.mat',\n",
            " 'dataset_type': 'imgaug',\n",
            " 'deterministic': False,\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'init_weights': '/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 1.0,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'mirror': False,\n",
            " 'net_type': 'resnet_50',\n",
            " 'num_joints': 4,\n",
            " 'optimizer': 'sgd',\n",
            " 'pairwise_huber_loss': True,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_predict': False,\n",
            " 'regularize': False,\n",
            " 'scoremap_dir': 'test',\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/My '\n",
            "                    'Drive/B-SOIDdlc-Dheyala-2022-07-05/dlc-models/iteration-0/B-SOIDdlcJul5-trainset95shuffle1/test/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running  DLC_resnet50_B-SOIDdlcJul5shuffle1_202000  with # of training iterations: 202000\n",
            "Running evaluation ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "320it [00:19, 16.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis is done and the results are stored (see evaluation-results) for snapshot:  snapshot-202000\n",
            "Results for 202000  training iterations: 95 1 train error: 2.09 pixels. Test error: 4.94  pixels.\n",
            "With pcutoff of 0.6  train error: 2.09 pixels. Test error: 4.94 pixels\n",
            "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
            "Plotting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "/* global mpl */\n",
              "window.mpl = {};\n",
              "\n",
              "mpl.get_websocket_type = function () {\n",
              "    if (typeof WebSocket !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof MozWebSocket !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert(\n",
              "            'Your browser does not have WebSocket support. ' +\n",
              "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
              "                'Firefox 4 and 5 are also supported but you ' +\n",
              "                'have to enable WebSockets in about:config.'\n",
              "        );\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = this.ws.binaryType !== undefined;\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById('mpl-warnings');\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent =\n",
              "                'This browser does not support binary websocket messages. ' +\n",
              "                'Performance may be slow.';\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = document.createElement('div');\n",
              "    this.root.setAttribute('style', 'display: inline-block');\n",
              "    this._root_extra_style(this.root);\n",
              "\n",
              "    parent_element.appendChild(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen = function () {\n",
              "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
              "        fig.send_message('send_image_mode', {});\n",
              "        if (fig.ratio !== 1) {\n",
              "            fig.send_message('set_device_pixel_ratio', {\n",
              "                device_pixel_ratio: fig.ratio,\n",
              "            });\n",
              "        }\n",
              "        fig.send_message('refresh', {});\n",
              "    };\n",
              "\n",
              "    this.imageObj.onload = function () {\n",
              "        if (fig.image_mode === 'full') {\n",
              "            // Full images could contain transparency (where diff images\n",
              "            // almost always do), so we need to clear the canvas so that\n",
              "            // there is no ghosting.\n",
              "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "        }\n",
              "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "    };\n",
              "\n",
              "    this.imageObj.onunload = function () {\n",
              "        fig.ws.close();\n",
              "    };\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._init_header = function () {\n",
              "    var titlebar = document.createElement('div');\n",
              "    titlebar.classList =\n",
              "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
              "    var titletext = document.createElement('div');\n",
              "    titletext.classList = 'ui-dialog-title';\n",
              "    titletext.setAttribute(\n",
              "        'style',\n",
              "        'width: 100%; text-align: center; padding: 3px;'\n",
              "    );\n",
              "    titlebar.appendChild(titletext);\n",
              "    this.root.appendChild(titlebar);\n",
              "    this.header = titletext;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function () {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
              "    canvas_div.setAttribute(\n",
              "        'style',\n",
              "        'border: 1px solid #ddd;' +\n",
              "            'box-sizing: content-box;' +\n",
              "            'clear: both;' +\n",
              "            'min-height: 1px;' +\n",
              "            'min-width: 1px;' +\n",
              "            'outline: 0;' +\n",
              "            'overflow: hidden;' +\n",
              "            'position: relative;' +\n",
              "            'resize: both;'\n",
              "    );\n",
              "\n",
              "    function on_keyboard_event_closure(name) {\n",
              "        return function (event) {\n",
              "            return fig.key_event(event, name);\n",
              "        };\n",
              "    }\n",
              "\n",
              "    canvas_div.addEventListener(\n",
              "        'keydown',\n",
              "        on_keyboard_event_closure('key_press')\n",
              "    );\n",
              "    canvas_div.addEventListener(\n",
              "        'keyup',\n",
              "        on_keyboard_event_closure('key_release')\n",
              "    );\n",
              "\n",
              "    this._canvas_extra_style(canvas_div);\n",
              "    this.root.appendChild(canvas_div);\n",
              "\n",
              "    var canvas = (this.canvas = document.createElement('canvas'));\n",
              "    canvas.classList.add('mpl-canvas');\n",
              "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
              "\n",
              "    this.context = canvas.getContext('2d');\n",
              "\n",
              "    var backingStore =\n",
              "        this.context.backingStorePixelRatio ||\n",
              "        this.context.webkitBackingStorePixelRatio ||\n",
              "        this.context.mozBackingStorePixelRatio ||\n",
              "        this.context.msBackingStorePixelRatio ||\n",
              "        this.context.oBackingStorePixelRatio ||\n",
              "        this.context.backingStorePixelRatio ||\n",
              "        1;\n",
              "\n",
              "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
              "        'canvas'\n",
              "    ));\n",
              "    rubberband_canvas.setAttribute(\n",
              "        'style',\n",
              "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
              "    );\n",
              "\n",
              "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
              "    if (this.ResizeObserver === undefined) {\n",
              "        if (window.ResizeObserver !== undefined) {\n",
              "            this.ResizeObserver = window.ResizeObserver;\n",
              "        } else {\n",
              "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
              "            this.ResizeObserver = obs.ResizeObserver;\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
              "        var nentries = entries.length;\n",
              "        for (var i = 0; i < nentries; i++) {\n",
              "            var entry = entries[i];\n",
              "            var width, height;\n",
              "            if (entry.contentBoxSize) {\n",
              "                if (entry.contentBoxSize instanceof Array) {\n",
              "                    // Chrome 84 implements new version of spec.\n",
              "                    width = entry.contentBoxSize[0].inlineSize;\n",
              "                    height = entry.contentBoxSize[0].blockSize;\n",
              "                } else {\n",
              "                    // Firefox implements old version of spec.\n",
              "                    width = entry.contentBoxSize.inlineSize;\n",
              "                    height = entry.contentBoxSize.blockSize;\n",
              "                }\n",
              "            } else {\n",
              "                // Chrome <84 implements even older version of spec.\n",
              "                width = entry.contentRect.width;\n",
              "                height = entry.contentRect.height;\n",
              "            }\n",
              "\n",
              "            // Keep the size of the canvas and rubber band canvas in sync with\n",
              "            // the canvas container.\n",
              "            if (entry.devicePixelContentBoxSize) {\n",
              "                // Chrome 84 implements new version of spec.\n",
              "                canvas.setAttribute(\n",
              "                    'width',\n",
              "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
              "                );\n",
              "                canvas.setAttribute(\n",
              "                    'height',\n",
              "                    entry.devicePixelContentBoxSize[0].blockSize\n",
              "                );\n",
              "            } else {\n",
              "                canvas.setAttribute('width', width * fig.ratio);\n",
              "                canvas.setAttribute('height', height * fig.ratio);\n",
              "            }\n",
              "            canvas.setAttribute(\n",
              "                'style',\n",
              "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
              "            );\n",
              "\n",
              "            rubberband_canvas.setAttribute('width', width);\n",
              "            rubberband_canvas.setAttribute('height', height);\n",
              "\n",
              "            // And update the size in Python. We ignore the initial 0/0 size\n",
              "            // that occurs as the element is placed into the DOM, which should\n",
              "            // otherwise not happen due to the minimum size styling.\n",
              "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
              "                fig.request_resize(width, height);\n",
              "            }\n",
              "        }\n",
              "    });\n",
              "    this.resizeObserverInstance.observe(canvas_div);\n",
              "\n",
              "    function on_mouse_event_closure(name) {\n",
              "        return function (event) {\n",
              "            return fig.mouse_event(event, name);\n",
              "        };\n",
              "    }\n",
              "\n",
              "    rubberband_canvas.addEventListener(\n",
              "        'mousedown',\n",
              "        on_mouse_event_closure('button_press')\n",
              "    );\n",
              "    rubberband_canvas.addEventListener(\n",
              "        'mouseup',\n",
              "        on_mouse_event_closure('button_release')\n",
              "    );\n",
              "    rubberband_canvas.addEventListener(\n",
              "        'dblclick',\n",
              "        on_mouse_event_closure('dblclick')\n",
              "    );\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband_canvas.addEventListener(\n",
              "        'mousemove',\n",
              "        on_mouse_event_closure('motion_notify')\n",
              "    );\n",
              "\n",
              "    rubberband_canvas.addEventListener(\n",
              "        'mouseenter',\n",
              "        on_mouse_event_closure('figure_enter')\n",
              "    );\n",
              "    rubberband_canvas.addEventListener(\n",
              "        'mouseleave',\n",
              "        on_mouse_event_closure('figure_leave')\n",
              "    );\n",
              "\n",
              "    canvas_div.addEventListener('wheel', function (event) {\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        on_mouse_event_closure('scroll')(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.appendChild(canvas);\n",
              "    canvas_div.appendChild(rubberband_canvas);\n",
              "\n",
              "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
              "    this.rubberband_context.strokeStyle = '#000000';\n",
              "\n",
              "    this._resize_canvas = function (width, height, forward) {\n",
              "        if (forward) {\n",
              "            canvas_div.style.width = width + 'px';\n",
              "            canvas_div.style.height = height + 'px';\n",
              "        }\n",
              "    };\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
              "        event.preventDefault();\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus() {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function () {\n",
              "    var fig = this;\n",
              "\n",
              "    var toolbar = document.createElement('div');\n",
              "    toolbar.classList = 'mpl-toolbar';\n",
              "    this.root.appendChild(toolbar);\n",
              "\n",
              "    function on_click_closure(name) {\n",
              "        return function (_event) {\n",
              "            return fig.toolbar_button_onclick(name);\n",
              "        };\n",
              "    }\n",
              "\n",
              "    function on_mouseover_closure(tooltip) {\n",
              "        return function (event) {\n",
              "            if (!event.currentTarget.disabled) {\n",
              "                return fig.toolbar_button_onmouseover(tooltip);\n",
              "            }\n",
              "        };\n",
              "    }\n",
              "\n",
              "    fig.buttons = {};\n",
              "    var buttonGroup = document.createElement('div');\n",
              "    buttonGroup.classList = 'mpl-button-group';\n",
              "    for (var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            /* Instead of a spacer, we start a new button group. */\n",
              "            if (buttonGroup.hasChildNodes()) {\n",
              "                toolbar.appendChild(buttonGroup);\n",
              "            }\n",
              "            buttonGroup = document.createElement('div');\n",
              "            buttonGroup.classList = 'mpl-button-group';\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        var button = (fig.buttons[name] = document.createElement('button'));\n",
              "        button.classList = 'mpl-widget';\n",
              "        button.setAttribute('role', 'button');\n",
              "        button.setAttribute('aria-disabled', 'false');\n",
              "        button.addEventListener('click', on_click_closure(method_name));\n",
              "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
              "\n",
              "        var icon_img = document.createElement('img');\n",
              "        icon_img.src = '_images/' + image + '.png';\n",
              "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
              "        icon_img.alt = tooltip;\n",
              "        button.appendChild(icon_img);\n",
              "\n",
              "        buttonGroup.appendChild(button);\n",
              "    }\n",
              "\n",
              "    if (buttonGroup.hasChildNodes()) {\n",
              "        toolbar.appendChild(buttonGroup);\n",
              "    }\n",
              "\n",
              "    var fmt_picker = document.createElement('select');\n",
              "    fmt_picker.classList = 'mpl-widget';\n",
              "    toolbar.appendChild(fmt_picker);\n",
              "    this.format_dropdown = fmt_picker;\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = document.createElement('option');\n",
              "        option.selected = fmt === mpl.default_extension;\n",
              "        option.innerHTML = fmt;\n",
              "        fmt_picker.appendChild(option);\n",
              "    }\n",
              "\n",
              "    var status_bar = document.createElement('span');\n",
              "    status_bar.classList = 'mpl-message';\n",
              "    toolbar.appendChild(status_bar);\n",
              "    this.message = status_bar;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.send_message = function (type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function () {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
              "        fig.send_message('refresh', {});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
              "    var x0 = msg['x0'] / fig.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
              "    var x1 = msg['x1'] / fig.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0,\n",
              "        0,\n",
              "        fig.canvas.width / fig.ratio,\n",
              "        fig.canvas.height / fig.ratio\n",
              "    );\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
              "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
              "    for (var key in msg) {\n",
              "        if (!(key in fig.buttons)) {\n",
              "            continue;\n",
              "        }\n",
              "        fig.buttons[key].disabled = !msg[key];\n",
              "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
              "    if (msg['mode'] === 'PAN') {\n",
              "        fig.buttons['Pan'].classList.add('active');\n",
              "        fig.buttons['Zoom'].classList.remove('active');\n",
              "    } else if (msg['mode'] === 'ZOOM') {\n",
              "        fig.buttons['Pan'].classList.remove('active');\n",
              "        fig.buttons['Zoom'].classList.add('active');\n",
              "    } else {\n",
              "        fig.buttons['Pan'].classList.remove('active');\n",
              "        fig.buttons['Zoom'].classList.remove('active');\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function () {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message('ack', {});\n",
              "};\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            var img = evt.data;\n",
              "            if (img.type !== 'image/png') {\n",
              "                /* FIXME: We get \"Resource interpreted as Image but\n",
              "                 * transferred with MIME type text/plain:\" errors on\n",
              "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "                 * to be part of the websocket stream */\n",
              "                img.type = 'image/png';\n",
              "            }\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src\n",
              "                );\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                img\n",
              "            );\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        } else if (\n",
              "            typeof evt.data === 'string' &&\n",
              "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
              "        ) {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig['handle_' + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\n",
              "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
              "                msg\n",
              "            );\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\n",
              "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
              "                    e,\n",
              "                    e.stack,\n",
              "                    msg\n",
              "                );\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "};\n",
              "\n",
              "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function (e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e) {\n",
              "        e = window.event;\n",
              "    }\n",
              "    if (e.target) {\n",
              "        targ = e.target;\n",
              "    } else if (e.srcElement) {\n",
              "        targ = e.srcElement;\n",
              "    }\n",
              "    if (targ.nodeType === 3) {\n",
              "        // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "    }\n",
              "\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    var boundingRect = targ.getBoundingClientRect();\n",
              "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
              "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
              "\n",
              "    return { x: x, y: y };\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * https://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys(original) {\n",
              "    return Object.keys(original).reduce(function (obj, key) {\n",
              "        if (typeof original[key] !== 'object') {\n",
              "            obj[key] = original[key];\n",
              "        }\n",
              "        return obj;\n",
              "    }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function (event, name) {\n",
              "    var canvas_pos = mpl.findpos(event);\n",
              "\n",
              "    if (name === 'button_press') {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * this.ratio;\n",
              "    var y = canvas_pos.y * this.ratio;\n",
              "\n",
              "    this.send_message(name, {\n",
              "        x: x,\n",
              "        y: y,\n",
              "        button: event.button,\n",
              "        step: event.step,\n",
              "        guiEvent: simpleKeys(event),\n",
              "    });\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.key_event = function (event, name) {\n",
              "    // Prevent repeat events\n",
              "    if (name === 'key_press') {\n",
              "        if (event.key === this._key) {\n",
              "            return;\n",
              "        } else {\n",
              "            this._key = event.key;\n",
              "        }\n",
              "    }\n",
              "    if (name === 'key_release') {\n",
              "        this._key = null;\n",
              "    }\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.key !== 'Control') {\n",
              "        value += 'ctrl+';\n",
              "    }\n",
              "    else if (event.altKey && event.key !== 'Alt') {\n",
              "        value += 'alt+';\n",
              "    }\n",
              "    else if (event.shiftKey && event.key !== 'Shift') {\n",
              "        value += 'shift+';\n",
              "    }\n",
              "\n",
              "    value += 'k' + event.key;\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
              "    return false;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
              "    if (name === 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message('toolbar_button', { name: name });\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "\n",
              "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
              "// prettier-ignore\n",
              "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";/* global mpl */\n",
              "\n",
              "var comm_websocket_adapter = function (comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.binaryType = comm.kernel.ws.binaryType;\n",
              "    ws.readyState = comm.kernel.ws.readyState;\n",
              "    function updateReadyState(_event) {\n",
              "        if (comm.kernel.ws) {\n",
              "            ws.readyState = comm.kernel.ws.readyState;\n",
              "        } else {\n",
              "            ws.readyState = 3; // Closed state.\n",
              "        }\n",
              "    }\n",
              "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
              "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
              "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
              "\n",
              "    ws.close = function () {\n",
              "        comm.close();\n",
              "    };\n",
              "    ws.send = function (m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function (msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        var data = msg['content']['data'];\n",
              "        if (data['blob'] !== undefined) {\n",
              "            data = {\n",
              "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
              "            };\n",
              "        }\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(data);\n",
              "    });\n",
              "    return ws;\n",
              "};\n",
              "\n",
              "mpl.mpl_figure_comm = function (comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = document.getElementById(id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm);\n",
              "\n",
              "    function ondownload(figure, _format) {\n",
              "        window.open(figure.canvas.toDataURL());\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element;\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error('Failed to find cell for figure', id, fig);\n",
              "        return;\n",
              "    }\n",
              "    fig.cell_info[0].output_area.element.on(\n",
              "        'cleared',\n",
              "        { fig: fig },\n",
              "        fig._remove_fig_handler\n",
              "    );\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
              "    var width = fig.canvas.width / fig.ratio;\n",
              "    fig.cell_info[0].output_area.element.off(\n",
              "        'cleared',\n",
              "        fig._remove_fig_handler\n",
              "    );\n",
              "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable();\n",
              "    fig.parent_element.innerHTML =\n",
              "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "    fig.close_ws(fig, msg);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width / this.ratio;\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] =\n",
              "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function () {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message('ack', {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () {\n",
              "        fig.push_to_output();\n",
              "    }, 1000);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function () {\n",
              "    var fig = this;\n",
              "\n",
              "    var toolbar = document.createElement('div');\n",
              "    toolbar.classList = 'btn-toolbar';\n",
              "    this.root.appendChild(toolbar);\n",
              "\n",
              "    function on_click_closure(name) {\n",
              "        return function (_event) {\n",
              "            return fig.toolbar_button_onclick(name);\n",
              "        };\n",
              "    }\n",
              "\n",
              "    function on_mouseover_closure(tooltip) {\n",
              "        return function (event) {\n",
              "            if (!event.currentTarget.disabled) {\n",
              "                return fig.toolbar_button_onmouseover(tooltip);\n",
              "            }\n",
              "        };\n",
              "    }\n",
              "\n",
              "    fig.buttons = {};\n",
              "    var buttonGroup = document.createElement('div');\n",
              "    buttonGroup.classList = 'btn-group';\n",
              "    var button;\n",
              "    for (var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            /* Instead of a spacer, we start a new button group. */\n",
              "            if (buttonGroup.hasChildNodes()) {\n",
              "                toolbar.appendChild(buttonGroup);\n",
              "            }\n",
              "            buttonGroup = document.createElement('div');\n",
              "            buttonGroup.classList = 'btn-group';\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        button = fig.buttons[name] = document.createElement('button');\n",
              "        button.classList = 'btn btn-default';\n",
              "        button.href = '#';\n",
              "        button.title = name;\n",
              "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
              "        button.addEventListener('click', on_click_closure(method_name));\n",
              "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
              "        buttonGroup.appendChild(button);\n",
              "    }\n",
              "\n",
              "    if (buttonGroup.hasChildNodes()) {\n",
              "        toolbar.appendChild(buttonGroup);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = document.createElement('span');\n",
              "    status_bar.classList = 'mpl-message pull-right';\n",
              "    toolbar.appendChild(status_bar);\n",
              "    this.message = status_bar;\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = document.createElement('div');\n",
              "    buttongrp.classList = 'btn-group inline pull-right';\n",
              "    button = document.createElement('button');\n",
              "    button.classList = 'btn btn-mini btn-primary';\n",
              "    button.href = '#';\n",
              "    button.title = 'Stop Interaction';\n",
              "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
              "    button.addEventListener('click', function (_evt) {\n",
              "        fig.handle_close(fig, {});\n",
              "    });\n",
              "    button.addEventListener(\n",
              "        'mouseover',\n",
              "        on_mouseover_closure('Stop Interaction')\n",
              "    );\n",
              "    buttongrp.appendChild(button);\n",
              "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
              "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
              "    var fig = event.data.fig;\n",
              "    if (event.target !== this) {\n",
              "        // Ignore bubbled events from children.\n",
              "        return;\n",
              "    }\n",
              "    fig.close_ws(fig, {});\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function (el) {\n",
              "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
              "    // this is important to make the div 'focusable\n",
              "    el.setAttribute('tabindex', 0);\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    } else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which === 13) {\n",
              "        this.canvas_div.blur();\n",
              "        // select the cell after this one\n",
              "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
              "        IPython.notebook.select(index + 1);\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "};\n",
              "\n",
              "mpl.find_output_cell = function (html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i = 0; i < ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code') {\n",
              "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] === html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "};\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel !== null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target(\n",
              "        'matplotlib',\n",
              "        mpl.mpl_figure_comm\n",
              "    );\n",
              "}\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id='ac212fe1-e3c3-4052-b175-e072d099d73d'></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [01:10<00:00,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
            "Please check the results, then choose the best model (snapshot) for prediction. You can update the config.yaml file with the appropriate index for the 'snapshotindex'.\n",
            "Use the function 'analyze_video' to make predictions on new videos.\n",
            "Otherwise, consider adding more labeled-data and retraining the network (see DeepLabCut workflow Fig 2, Nath 2019)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaLBl3TQtrfB"
      },
      "source": [
        "## There is an optional refinement step you can do outside of Colab:\n",
        "- if your pixel errors are not low enough, please check out the protocol guide on how to refine your network!\n",
        "- You will need to adjust the labels **outside of Colab!** We recommend coming back to train and analyze videos... \n",
        "- Please see the repo and protocol instructions on how to refine your data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVFLSKKfoEJk"
      },
      "source": [
        "## Start Analyzing videos: \n",
        "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
        "\n",
        "The results are stored in hd5 file in the same directory where the video resides. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_LZiS_0oEJl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48dd2fab-1087-4398-cdf1-4c7b53008e7b"
      },
      "source": [
        "deeplabcut.analyze_videos(path_config_file,videofile_path, videotype=VideoType)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config:\n",
            "{'all_joints': [[0], [1], [2], [3]],\n",
            " 'all_joints_names': ['nose', 'leftear', 'rightear', 'tailbase'],\n",
            " 'batch_size': 1,\n",
            " 'crop_pad': 0,\n",
            " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_B-SOIDdlcJul5/B-SOIDdlc_Dheyala95shuffle1.mat',\n",
            " 'dataset_type': 'imgaug',\n",
            " 'deterministic': False,\n",
            " 'fg_fraction': 0.25,\n",
            " 'global_scale': 0.8,\n",
            " 'init_weights': '/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
            " 'intermediate_supervision': False,\n",
            " 'intermediate_supervision_layer': 12,\n",
            " 'location_refinement': True,\n",
            " 'locref_huber_loss': True,\n",
            " 'locref_loss_weight': 1.0,\n",
            " 'locref_stdev': 7.2801,\n",
            " 'log_dir': 'log',\n",
            " 'mean_pixel': [123.68, 116.779, 103.939],\n",
            " 'mirror': False,\n",
            " 'net_type': 'resnet_50',\n",
            " 'num_joints': 4,\n",
            " 'optimizer': 'sgd',\n",
            " 'pairwise_huber_loss': True,\n",
            " 'pairwise_predict': False,\n",
            " 'partaffinityfield_predict': False,\n",
            " 'regularize': False,\n",
            " 'scoremap_dir': 'test',\n",
            " 'shuffle': True,\n",
            " 'snapshot_prefix': '/content/drive/My '\n",
            "                    'Drive/B-SOIDdlc-Dheyala-2022-07-05/dlc-models/iteration-0/B-SOIDdlcJul5-trainset95shuffle1/test/snapshot',\n",
            " 'stride': 8.0,\n",
            " 'weigh_negatives': False,\n",
            " 'weigh_only_present_joints': False,\n",
            " 'weigh_part_predictions': False,\n",
            " 'weight_decay': 0.0001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using snapshot-202000 for model /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/dlc-models/iteration-0/B-SOIDdlcJul5-trainset95shuffle1\n",
            "Analyzing all the videos in the directory...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse7-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse7-e.mp4\n",
            "Duration of video [s]:  161.56 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4842  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 4800/4842 [02:12<00:01, 36.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse9-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse9-e.mp4\n",
            "Duration of video [s]:  178.24 , recorded with  29.97 fps!\n",
            "Overall # of frames:  5342  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 5300/5342 [02:31<00:01, 34.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse11-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse11-e.mp4\n",
            "Duration of video [s]:  151.35 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4536  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 4500/4536 [02:11<00:01, 34.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse2-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse2-e.mp4\n",
            "Duration of video [s]:  151.92 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4553  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 4545/4553 [02:12<00:00, 34.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse15-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse15-e.mp4\n",
            "Duration of video [s]:  151.25 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4533  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 4500/4533 [02:11<00:00, 34.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse10-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse10-e.mp4\n",
            "Duration of video [s]:  151.02 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4526  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 4500/4526 [02:11<00:00, 34.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse14-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse14-e.mp4\n",
            "Duration of video [s]:  150.92 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4523  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 4500/4523 [02:11<00:00, 34.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse3-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse3-e.mp4\n",
            "Duration of video [s]:  156.92 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4703  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 4700/4703 [02:16<00:00, 34.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse12-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse12-e.mp4\n",
            "Duration of video [s]:  150.72 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4517  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 4500/4517 [02:11<00:00, 34.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse6-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse6-e.mp4\n",
            "Duration of video [s]:  156.16 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4680  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 4646/4680 [02:15<00:00, 34.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse8-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse8-e.mp4\n",
            "Duration of video [s]:  153.69 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4606  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 4600/4606 [02:13<00:00, 34.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse13-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse13-e.mp4\n",
            "Duration of video [s]:  151.25 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4533  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 4500/4533 [02:11<00:00, 34.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse5-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse5-e.mp4\n",
            "Duration of video [s]:  154.69 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4636  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 4600/4636 [02:14<00:01, 34.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse1 -e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse1 -e.mp4\n",
            "Duration of video [s]:  152.75 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4578  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 4545/4578 [02:12<00:00, 34.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse16-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse16-e.mp4\n",
            "Duration of video [s]:  151.02 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4526  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 4500/4526 [02:11<00:00, 34.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "Starting to analyze %  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse4-e.mp4\n",
            "Loading  /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos/mouse4-e.mp4\n",
            "Duration of video [s]:  152.62 , recorded with  29.97 fps!\n",
            "Overall # of frames:  4574  found with (before cropping) frame dimensions:  720 480\n",
            "Starting to extract posture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 4545/4574 [02:12<00:00, 34.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/drive/My Drive/B-SOIDdlc-Dheyala-2022-07-05/videos...\n",
            "The videos are analyzed. Now your research can truly start! \n",
            " You can create labeled videos with 'create_labeled_video'\n",
            "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DLC_resnet50_B-SOIDdlcJul5shuffle1_202000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GTiuJESoEKH"
      },
      "source": [
        "## Plot the trajectories of the analyzed videos:\n",
        "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX21zZbXoEKJ",
        "outputId": "509fd67a-bbc1-47ab-991e-14c20c2e25b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "deeplabcut.plot_trajectories(path_config_file,videofile_path, mp4=VideoType)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-acac7ebb12ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_trajectories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvideofile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVideoType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'deeplabcut' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqaCw15v8EmB"
      },
      "source": [
        "Now you can look at the plot-poses file and check the \"plot-likelihood.png\" might want to change the \"p-cutoff\" in the config.yaml file so that you have only high confidnece points plotted in the video. i.e. ~0.8 or 0.9. The current default is 0.4. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCrUvQIvoEKD"
      },
      "source": [
        "## Create labeled video:\n",
        "This function is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aDF7Q7KoEKE"
      },
      "source": [
        "deeplabcut.create_labeled_video(path_config_file,videofile_path, videotype=VideoType)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}